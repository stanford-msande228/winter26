---
title: Causal Estimation with Machine Learning
---

Jan 20
: **Lecture 8**{: .label .label-green } Flexible Causal Estimation with Machine Learning: Debiased Machine Learning I
    : [[Slides]](https://github.com/stanford-msande228/winter26/raw/main/assets/presentations/MSANDE228_Lecture4.pdf)
    : [[Notes]](https://github.com/stanford-msande228/winter26/raw/main/assets/presentations/lecture_notes/lecture4_student_notes.pdf)
    : [[NotebookLM]](https://notebooklm.google.com/notebook/b72fc5a1-42cb-4a9c-a66e-f5aeeed72f6e?authuser=1)
: Confidence intervals and asymptotic normality, Why naive ML is problematic for confidence intervals of causal quantities, The doubly robust estimator, cross-fitting, semi-cross-fitting.
: ***Reading Materials***
- [Textbook: Chapter 9](http://www.causalml-book.org)
- Chernozhukov et al. (2018), Double/debiased machine learning for treatment and structural parameters (optional)
- Bang & Robins (2005), Doubly robust estimation in missing data and causal inference (optional)

Jan 21
: **Homework**{: .label .label-blue } HW2 Released, Wednesday (Doubly Robust Estimation)


Jan 22
: **Lecture 8**{: .label .label-green } Flexible Causal Estimation with Machine Learning: Debiased Machine Learning II
: Solving Prediction Problems with 
ML 
: ***Reading Materials***
- [Textbook: Chapters 1, 3, 8](http://www.causalml-book.org)


Jan 27
: **Lecture 6**{: .label .label-green } Linear Regression for Causal Inference
: Analyzing Experiments with Precision, FWL & Partialling Out
: ***Reading Materials***
- [Textbook: Chapter 1](http://www.causalml-book.org)
- [Textbook: Chapter 2](http://www.causalml-book.org)
- Angrist & Pischke, Mostly Harmless Econometrics (optional background)
- Lin (2013), Agnostic notes on regression adjustments to experimental data (optional)
: ***Coding Materials***
- [Pennsylvania Re-employment Bonus Experiment (notebook)](https://github.com/CausalAIBook/MetricsMLNotebooks/blob/main/CM1/python-rct-penn-precision-adj.ipynb)
- [Simulated precision via adjustment (notebook)](https://github.com/CausalAIBook/MetricsMLNotebooks/blob/main/CM1/python-sim-precision-adj.ipynb)

Jan 28
: **Homework**{: .label .label-red } HW2 Due, Wednesday

Jan 28
: **Homework**{: .label .label-blue } HW3 Released, Wednesday (Analyzing Experiments with Precision)

Jan 29
: **Lecture 7**{: .label .label-green } Inference with High-Dimensional Linear Models
: Analyzing Experiments with Precision in High-Dimensions, FWL & Partialling Out for High-Dimensional Linear Models, Double Lasso
: ***Reading Materials***
- [Textbook: Chapters 3 and 4](http://www.causalml-book.org)
- Belloni, Chernozhukov & Hansen (2014), Inference on treatment effects after selection amongst high-dimensional controls (optional)


Feb 3
: **Homework**{: .label .label-red } HW3 Due, Tuesday

Feb 3
: **Lecture 9**{: .label .label-green } General Debiased Machine Learning Framework
: Partially Linear Models, Continuous Treatments, Generalized FWL theorem, Parameters defined via moment restrictions and the general principle of Neyman orthogonality
: ***Reading Materials***
- [Textbook: Section 9.4](http://www.causalml-book.org)



Feb 3
: **Homework**{: .label .label-blue } HW4 Released, Tuesday (Partially Linear Models)